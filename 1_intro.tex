There has recently been a shift in the focus of computer hardware manufacturers. Most manufacturers spent their research and development on increasing the clock speed of their hardware to make computation faster. However, lately has been a plateau on clock speed resulting in a new way to increase processing speed. The way many manufacturers are increasing the computational power of computers is by adding multiple computational cores on a  single chip. This allows programs to run multiple computations at the same time which can cut the runtime of processes drastically. Multiple cores have been common on larger hardware, such as GPUs, but there hasn't been much focus on truly expanding the number of cores on a CPU. However, with multiple cores becoming more common programmers will need to be able to make use of them effectively if they want to gain any benefit. Admittedly, there are some applications that multiple cores can't increase performance; however, many applications can be easily converted to run parallel on multiple cores.

Although many applications can be easily be converted to run parallel, some languages make that task less trivial than it should be. The design of new languages that are intended to be used for parallel computation is vital to the advancement of computation. Some languages try to build libraries into the language to handle this multiple core processing, such as Java, but they are hard to work with. In this paper we are going to discuss concurrent programming languages and what affect they have on basic and advance programs. We will be focusing on Go (a language created by Google and used for servers), Swift (a programming language that focuses on increasing time performance of other applications for scientific programming), and Clojure (a dynamic, Lisp dialect with a focus on concurrency).

\subsection{Programming Problem}
    The problem we will be solving is a simple two matrix multiplication. The reason we chose this problem is because it is an operation that is typically handled by an external library, such as NumPy \cite{numpy}, but can easily be parallelized as it is many discrete operations that are independent of one another. We will be multiplying square matrices of the following sizes: 100, 250, 500, 750, 1000, 1500, 2000. With this we will be able to show how performance changes with increased data size. We will compare the languages mentioned earlier to the Thread implementation of Java. Since Java is not optimized to be a parallel programming language we are expecting each of the optimized languages to exceed its performance.

\subsection{Concurrency Limit \& Bandwidth}
    The limit of concurrency is dependent on not only how much you can work on your problem separately, but also a limitation on hardware and bandwidth. Our given programming problem is an easy problem to apply concurrently, but we can't run 200 threads with only 8 cores, and as we parallelize our threads, we will find a lower utilization in general for a single thread that could lead to a longer execution time. This bottlenecking is a common issue in concurrency, but is one of several. Although concurrency is incredibly important for performance, large amounts can lead to issues with memory bandwidth and cache\cite{cuppu2001concurrency}, which can cause bottle-necking. This could be a limitation for our matricies as well, leading to negative results with incredibly large matrix multiplication.
