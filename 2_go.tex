\goColor
\subsection{Introduction to the Go Programing Language}
	The Go programming language was designed by Robert Griesemer, Rob Pike and Ken Thompson. A portion of their design focused on creating a new language with support for networked and multi-core computing. Go’s concurrency implementation builds upon ideas from past languages, such as Newsqueak, Alef and Limbo, and C.A.R. Hoare’s 1978 paper, Communicating Sequential Processes (CSP), a formal language for writing concurrent programs. \cite{prell:hal-00718924} This implementation differs from the usual methodology of locks and threads.
	The core principle of Go is to reduce complexities present in modern programming languages and concurrent programming is one such complexity. The new language provides an approach in which shared values are easily passed between sequential processes. The medium of communication, variable passing, is referred to as a channel. CSP introduced the concept of channels for interprocess communication in a book written by Hoare, published after his original paper. This method of operation, in which processes (goroutines) communicate through channels, is analogous to the programming style of message passing. The use of channels ensures that variables are never actively chard by separate processes, thus data races can never occur. The Go concurrent methodology can be reduced to its slogan, “Do not communicate by sharing memory; instead, share memory by communicating”. \cite{website:go-lang-documentation}
	Go’s concurrent programming is based on two fundamentals, goroutines and channels. Goroutines have a simple model and can be thought as lightweight threads. Channels serve to handle both communication and synchronization. By default Go’s channels are synchronous, and channels are unbuffered when a buffer size is not specified. \cite{prell:hal-00718924} The specifics of Go’s channel will be discussed later, but first we will cover goroutines, for channels exist to serve them. Lastly, we will discuss parallelization in Go and apply it within our matrix multiplication code.
\subsection{Goroutines}
	The term goroutine was made because existing terms for concurrent processes, such as threads, coroutines, process, etc., convey a meaning that inaccurately describes how Go executes functions concurrently. The goroutine model is simple and lightweight, hiding man of the complexities of thread creation and management. Goroutines execute in the same address space, and memory allocation starts at the cost of a small stack space and grows by allocating and freeing as heap storage requires. Goroutines are multiplexed onto OS threads, not process threads, therefore in one goroutine is to block the others will continue to execute.\cite{website:go-lang-documentation}
	A goroutine is created simply by prefixing the keyword \emph{go} to a function call.
\begin{lstlisting}[language=Go]
go innerprod(a, b, ch)
// Execute the inner product function
// concurrently as a goroutine,
// do not wait for it to finish.
\end{lstlisting}
Function innerprod(a, b, ch) takes the inner product of a row vector \emph{a} and column vector \emph{b}. The parameter \emph{ch} is of type channel, which will be discussed thoroughly in the next section. Then, a detailed explination of the function will provided in our matrix multiplication program section. To digress, the important point here is to convey the simplicity of creating a goroutine, that any function may be run concurrently by prefixing the keyword \emph{go}. However, if the function does not recieve a channel, then the goroutine will not be able to properly return variables or signal its completion.
\begin{lstlisting}[language=Go]
func badgoroutine(a, b){
	result := go innerprod(a, b)
	fmt.Println(result)
}
\end{lstlisting}
A goroutine should never be used as shown above. In fact this code has created a race condition, and is general example of bad concurrent programming.
	One last feature to note, Go function lterals are closures, thus ensureing variables referred to by the function remain until they are no longer needed. A code snippet from the Golang documentation demostrates the use of a function literal in a goroutine function literal.
\begin{lstlisting}[language=Go]
func Announce(message string,
	delay time.Duration) {

    go func() {
        time.Sleep(delay)
        fmt.Println(message)
    }()
    /* Note the parentheses - must
       call the function. */
}.
\end{lstlisting}
\subsection{Channels}
Channels use the make function to allocate themselves, the resulting value references the underlying data structure. If you add an integer value as a second parameter (you do not have to add an integer as the second parameter because it is optional) it sets the buffer size of that channel. For example (all following examples were obtained from \cite{website:go-lang-documentation}):
\begin{lstlisting}[language=Go]
ci := make(chan int)
\end{lstlisting}
Creates a channel on integers that is unbuffered. Interestingly because the second parameter is optional if not entered its default is 0 so it is the same as coding:
\begin{lstlisting}[language=Go]
cj := make(chan int, 0)
\end{lstlisting}
But if you do enter something other than 0 like follows:
\begin{lstlisting}[language=Go]
cs := make(chan int, 100)
\end{lstlisting}
It creates a buffered channel of pointers to integers.
If a channel is unbuffered Go will use a combination of communication and synchronization to ensure that the goroutines are within a known state.  A use full demonstration of using channels with goroutines is to having a channel on a variable do a sort within goroutine. Then give a value to that while everything outside the routine continues until it arrives at the channeled variable. This would cause it to wait until the goroutine operating on the variable has finished before continuing.  This is a general implementation of what I have just described:
\begin{lstlisting}[language=Go]
c := make(chan int)
/* makes an unbuffered
   channel of type int.
   Start a goroutine wait for
   it to complete then signal
   on the channel. */
go func() {
    list.Sort()// sorts some list
    c <- 1
    /* Send a signal,
       the value does not matter
       or this demonstration. */
}()
doSomethingForAWhile()
<-c   // Waits for sort to finish;
\end{lstlisting}
The blockers, in this case c, will block until data is received. If the channel is an unbuffered channel the sender will block until it receives a value. Otherwise if the channel is buffered the sender only blocks as until the buffer has been filled. This mean that if a buffer is full it will wait until a receiver tries to retrieve it.
	A buffered channel can be used as a type of semaphore. For instance this example limits throughput:
\begin{lstlisting}[language=Go]
func handle(queue chan *Request) {
    for r := range queue {
        process(r)
    }
}

func Serve(clientRequests chan
	*Request, quit chan bool) {

    // Start handlers
    for i := 0; i < MaxOutstanding;
    i++ {
        go handle(clientRequests)
    }
    <-quit
   // Wait to be told to exit.
}
\end{lstlisting}
A very important property to remember in go is the first class values can be passed around like any other values. This can be used to to create safe and parallel demultiplexing. As an example we will be dissecting the handle function from above. If you recall, in the previous example, we did not define the type it was handling. If they type has a channel where it can reply the client is able to determine it own path to the answer. This is a schematic of type Result :
\begin{lstlisting}[language=Go]
type Request struct {
    args        []int
    f           func([]int) int
    resultChan  chan int
}
\end{lstlisting}
The client gives a function, argument, and channel inside a request object to receive the answer.
\begin{lstlisting}[language=Go]
func sum(a []int) (s int) {
    for _, v := range a {
        s += v
    }
    return
}

request := &Request{[]int{3, 4, 5},
	 	sum, make(chan int)}
// Send request
clientRequests <- request
// Wait for response.
fmt.Printf("answer: %d\n",
		<-request.resultChan)
\end{lstlisting}
On the back end the handler is the only thing that changes.
\begin{lstlisting}[language=Go]
func handle(queue chan *Request) {
    for req := range queue {
        req.resultChan <- req.f(
			    req.args)
    }
}
\end{lstlisting}
This is the general framework for a rate-limited, parallel, non-blocking RPC system.
\subsection{Parallelization}
“Another application of these ideas is to parallelize a calculation across multiple CPU cores. If the calculation can be broken into separate pieces that can execute independently, it can be parallelized, with a channel to signal when each piece completes.”\cite{website:go-lang-documentation}
\emph{Parrallelization is to be discussed in more details.}
\subsection{Concurrent Matrix Multiplication Results}
\emph{Code and results to be added later.}
